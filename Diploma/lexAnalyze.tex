\subsection{Лексический анализатор} \label{sub112}

Основная задача лексического анализатора состоит в чтении входных символов исходной программы, их группировании в лексемы и вывод последовательностей токенов для всех лексем исходной программы. Поток токенов пересылается синтаксическому анализатору для разбора. Также лексический анализатор может удалять комментарии, пробельные символы, синхронизировать сообщения об ошибках или раскрывать макросы.

При рассмотрении лексического анализа используются четыре связанных, но различных термина:

\begin{itemize} 
	\item{\textit{Токен} (от англ. \textit{token}~--- знак, символ) представляет собой пару, состоящую из имени токена и необязательного атрибута. Имя токена~--- абстрактный символ, представляющий тип лексической единицы, например конкретное ключевое слово или последовательность символов, составляющих идентификатор. Имена токенов являются входными символами, обрабатываемыми синтаксическим анализатором.}
	\item{\textit{Шаблон}~--- это описание вида, который может принимать лексема токена. В случае ключевого слова шаблон представляет собой последовательность символов, образующая это ключевое слово. Для некоторых токенов шаблон представляет более сложную структуру.}
	\item{\textit{Лексема}~--- последовательность символов исходной программы, которая соответствует шаблону токена и идентифицируется лексическим анализатором как экзепляр токена.}
	\item{\textit{Атрибут токена}~--- строка или структура, объединяющая несколько блоков информации, которая содержит значение числа, в случае если токен соответствует шаблону числа, или описание лексемы (строчка кода, значение) которая представляет токен. \todo{Пример будет}}
\end{itemize}


\todo{Таблица примеров токена будет}